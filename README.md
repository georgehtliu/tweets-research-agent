# Grok Agentic Research Workflow

An autonomous multi-step agentic workflow using Grok as the central reasoner for complex research on simulated X (Twitter) data.

## ğŸ¯ Overview

This system implements a fully autonomous research agent that can:
- **Plan**: Break down complex queries into actionable steps
- **Execute**: Retrieve relevant data using hybrid search (semantic + keyword)
- **Analyze**: Deep analysis of retrieved information
- **Refine**: Iteratively improve results when confidence is low
- **Summarize**: Generate comprehensive final summaries

The agent handles various query types:
- Trend analysis
- Information extraction
- Comparative analysis
- Temporal analysis
- Sentiment analysis
- And more...

## ğŸ—ï¸ Architecture Overview

### System Architecture

The system follows a **state machine pattern** with autonomous decision-making capabilities:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Query Input                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   State Machine       â”‚
            â”‚   Orchestrator        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚               â”‚
        â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PLAN       â”‚ â”‚   EXECUTE    â”‚ â”‚   ANALYZE    â”‚
â”‚              â”‚ â”‚              â”‚ â”‚              â”‚
â”‚ - Decompose  â”‚ â”‚ - Tool Call  â”‚ â”‚ - Extract    â”‚
â”‚ - Classify   â”‚ â”‚ - Hybrid     â”‚ â”‚   Themes     â”‚
â”‚ - Select     â”‚ â”‚   Search     â”‚ â”‚ - Sentiment  â”‚
â”‚   Tools      â”‚ â”‚ - Filter     â”‚ â”‚ - Confidence â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚                 â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚     EVALUATE          â”‚
            â”‚  (Replan Decision)    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                       â”‚
        Replan?                  No
            â”‚                       â”‚
            â–¼                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   REFINE     â”‚      â”‚   CRITIQUE   â”‚
    â”‚              â”‚      â”‚              â”‚
    â”‚ - Iterative  â”‚      â”‚ - Hallucin.  â”‚
    â”‚   Improve    â”‚      â”‚   Check      â”‚
    â”‚ - Expand     â”‚      â”‚ - Bias Check â”‚
    â”‚   Search     â”‚      â”‚ - Quality    â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    SUMMARIZE          â”‚
            â”‚                       â”‚
            â”‚ - Executive Summary   â”‚
            â”‚ - Key Findings        â”‚
            â”‚ - Detailed Analysis   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Frontend (Web UI)                      â”‚
â”‚  - React-like vanilla JS                                    â”‚
â”‚  - Server-Sent Events (SSE) for real-time updates           â”‚
â”‚  - Model comparison interface                               â”‚
â”‚  - Tweets browsing page                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ HTTP/SSE
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI Server                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Query Routes â”‚  â”‚ Eval Routes  â”‚  â”‚ Main Routes  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                 â”‚                  â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                           â”‚                                  â”‚
â”‚                           â–¼                                  â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚              â”‚   Agent Service       â”‚                      â”‚
â”‚              â”‚  (Singleton Pattern)  â”‚                      â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AgenticResearchAgent (State Machine)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Context      â”‚  â”‚ Hybrid       â”‚  â”‚ Tool        â”‚     â”‚
â”‚  â”‚ Manager      â”‚  â”‚ Retriever    â”‚  â”‚ Registry    â”‚     â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚             â”‚     â”‚
â”‚  â”‚ - History    â”‚  â”‚ - Semantic   â”‚  â”‚ - Keyword   â”‚     â”‚
â”‚  â”‚ - Steps      â”‚  â”‚   Search     â”‚  â”‚   Search    â”‚     â”‚
â”‚  â”‚ - Tokens     â”‚  â”‚ - Keyword    â”‚  â”‚ - Temporal   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   Search     â”‚  â”‚ - Profile    â”‚     â”‚
â”‚                    â”‚ - Hybrid     â”‚  â”‚ - Filter     â”‚     â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â”‚                 â”‚              â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                    â”‚                       â”‚
â”‚                                    â–¼                       â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                          â”‚ Grok Client  â”‚                 â”‚
â”‚                          â”‚              â”‚                 â”‚
â”‚                          â”‚ - API Calls  â”‚                 â”‚
â”‚                          â”‚ - Streaming  â”‚                 â”‚
â”‚                          â”‚ - Tool Call  â”‚                 â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Grok API      â”‚
                        â”‚  (xAI Console)   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¨ Major Design Decisions

### 1. **State Machine Pattern for Workflow Orchestration**

**Decision**: Implemented a state machine with explicit state transitions rather than a linear pipeline.

**Rationale**:
- **Autonomy**: Enables the agent to make dynamic decisions (e.g., replanning when analysis reveals insufficient data)
- **Flexibility**: Supports conditional state transitions (e.g., `ANALYZE â†’ EVALUATE â†’ PLAN` if replan needed)
- **Clarity**: Makes the workflow explicit and debuggable
- **Extensibility**: Easy to add new states (e.g., `CRITIQUE` state for quality checks)

**Implementation**: `WorkflowState` enum with state transition logic in `run_workflow()` method.

### 2. **Hybrid Retrieval System**

**Decision**: Combined semantic search (embeddings) with keyword search rather than using either alone.

**Rationale**:
- **Robustness**: Semantic search handles conceptual queries; keyword search handles exact matches
- **Performance**: Keyword search is fast for specific terms; semantic search finds related content
- **Coverage**: Handles both "find posts about AI safety" (semantic) and "find posts with #Python" (keyword)
- **Fallback**: If embeddings fail, keyword search still works

**Implementation**: `HybridRetriever` combines cosine similarity (semantic) with TF-IDF-like scoring (keyword), weighted by `config.HYBRID_SEMANTIC_WEIGHT`.

### 3. **Dynamic Tool Calling**

**Decision**: Implemented OpenAI-style function calling for iterative tool selection, with a fallback to plan-based execution.

**Rationale**:
- **Adaptability**: Complex queries benefit from iterative tool selection based on intermediate results
- **Efficiency**: Simple queries use faster plan-based execution (no tool-calling overhead)
- **Autonomy**: Agent decides which tools to use based on context, not hardcoded logic
- **Extensibility**: Easy to add new tools without changing core workflow

**Implementation**: `ToolRegistry` provides tool definitions; planner decides `use_tool_calling` flag; `execute_with_tool_calling()` implements iterative loop.

### 4. **Context Management with Token Limits**

**Decision**: Implemented `ContextManager` to track execution history and manage context size.

**Rationale**:
- **Memory Efficiency**: Prevents context overflow by truncating old steps
- **Traceability**: Maintains execution history for debugging and analysis
- **Cost Control**: Tracks token usage to monitor API costs
- **Quality**: Preserves recent context while summarizing older steps

**Implementation**: `ContextManager` tracks `ExecutionStep` objects, truncates when approaching `MAX_CONTEXT_TOKENS`, uses `create_concise_data_summary()` for compression.

### 5. **Model Selection Strategy**

**Decision**: Use `grok-4-fast-reasoning` for all reasoning tasks rather than mixing models.

**Rationale**:
- **Cost Efficiency**: 45x cheaper than `grok-3` ($0.20/$0.50 vs $3/$15 per 1M tokens)
- **Large Context**: 2M token context window (vs 131K) enables better context management
- **Consistency**: Same model ensures consistent behavior across stages
- **Simplicity**: Easier configuration and maintenance

**Trade-off**: Could use lighter models for classification, but current approach prioritizes quality and simplicity.

**Implementation**: `ModelConfig` in `config.py` with `model_config` override support for model comparison.

### 6. **Fast Mode for Latency Reduction**

**Decision**: Added `fast_mode` flag to skip `EVALUATE` and `CRITIQUE` states for faster execution.

**Rationale**:
- **User Control**: Users can choose speed vs. quality trade-off
- **Use Cases**: Fast mode suitable for exploratory queries; full mode for production
- **Flexibility**: Can be enabled per-query or globally via config

**Implementation**: `fast_mode` parameter in `run_workflow()` skips `evaluate()` and `critique()` calls.

### 7. **Progress Callback System**

**Decision**: Implemented callback-based progress reporting for real-time UI updates.

**Rationale**:
- **User Experience**: Provides real-time feedback during long-running queries
- **Debugging**: Helps identify bottlenecks in the workflow
- **Flexibility**: Works for both CLI (print) and Web UI (SSE streaming)

**Implementation**: `progress_callback(event_type, data)` called at each workflow step; Web UI uses Server-Sent Events (SSE) for streaming.

### 8. **Modular Router Architecture**

**Decision**: Separated routes into `query_router`, `evaluation_router`, and `main_router`.

**Rationale**:
- **Separation of Concerns**: Each router handles a specific domain
- **Maintainability**: Easy to find and modify route handlers
- **Scalability**: Can add new routers without cluttering main app
- **Testing**: Each router can be tested independently

**Implementation**: FastAPI routers with prefixes (`/api` for query/eval, `/` for main).

### 9. **Embedding Caching**

**Decision**: Cache embeddings on disk to avoid recomputing for the same dataset.

**Rationale**:
- **Performance**: Embeddings are expensive to compute; caching saves time on subsequent runs
- **Cost**: Reduces CPU usage
- **Stability**: Uses data hash to detect dataset changes

**Implementation**: `HybridRetriever._load_or_build_embeddings()` checks cache directory; invalidates on data change.

### 10. **Parallel Model Comparison**

**Decision**: Run multiple models in parallel for comparison rather than sequentially.

**Rationale**:
- **Speed**: Parallel execution reduces total time
- **Fairness**: All models see the same query simultaneously
- **User Experience**: Faster results for comparison

**Implementation**: `ThreadPoolExecutor` in `/api/query/compare-models` endpoint; progress events streamed via queues.

### 11. **Error Handling and Resilience**

**Decision**: Comprehensive error handling with graceful degradation.

**Rationale**:
- **Reliability**: System continues operating even if components fail
- **User Experience**: Clear error messages instead of crashes
- **Debugging**: Detailed error logging for troubleshooting

**Implementation**: Try-catch blocks at critical points; fallback to keyword-only search if embeddings fail; division-by-zero guards in calculations.

### 12. **Mock Data Generation**

**Decision**: Generate diverse, realistic mock X data with multiple categories, languages, and edge cases.

**Rationale**:
- **Testing**: Enables testing without real API access
- **Diversity**: Covers various query types (trends, sentiment, multilingual, etc.)
- **Realism**: Includes verified accounts, engagement metrics, threads, etc.

**Implementation**: `MockXDataGenerator` with category-specific templates, foreign language support, and celebrity names.

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Grok API key from [console.x.ai](https://console.x.ai)
- Use promo code: `grok_eng_b4d86a51` for $20 free credits

### Installation

1. **Clone the repository**
```bash
git clone <your-repo-url>
cd Grok-takehome
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Set up environment variables**
```bash
cp .env.example .env
# Edit .env and add your GROK_API_KEY
```

4. **Generate mock data** (optional - will auto-generate on first run)
```bash
cd server
python data_generator.py
```

### Usage

#### Web UI (Recommended)
Start the API server:
```bash
cd server
python api_server.py
```

Or from project root:
```bash
python server/api_server.py
```

Then open your browser to:
```
http://localhost:8080
```

**Important**: Always access the UI through the server URL (`http://localhost:8080`), not by opening the HTML file directly. The server serves the frontend and handles API requests.

(You can change the port by setting the `PORT` environment variable)

The web interface provides:
- Simple query input with submit button
- Example queries to try
- Real-time results display
- Beautiful, responsive UI

#### CLI Mode

**Interactive Mode:**
```bash
cd server
python main.py
```

Or from project root:
```bash
python server/main.py
```

Then enter your query when prompted:
```
ğŸ’¬ Enter your research query: What are people saying about AI safety?
```

**Single Query Mode:**
```bash
cd server
python main.py --query "What are the main trends in tech discussions?"
```

**With Custom Data:**
```bash
cd server
python main.py --query "Your question" --data path/to/data.json
```

#### API Endpoints

The API server provides REST endpoints (FastAPI):

- `GET /` - Web UI
- `POST /api/query` - Submit research query (returns SSE stream)
  ```json
  {
    "query": "What are people saying about AI?"
  }
  ```
- `GET /api/health` - Health check
- `GET /api/examples` - Get example queries
- `GET /docs` - Swagger UI documentation
- `GET /redoc` - ReDoc documentation

## ğŸ“ Project Structure

```
Grok-takehome/
â”œâ”€â”€ server/                      # Server-side code
â”‚   â”œâ”€â”€ api_server.py            # FastAPI server entry point
â”‚   â”œâ”€â”€ main.py                  # CLI entry point
â”‚   â”œâ”€â”€ app.py                   # FastAPI app factory
â”‚   â”œâ”€â”€ agent.py                 # Core agentic workflow (state machine)
â”‚   â”œâ”€â”€ grok_client.py           # Grok API client with tool calling
â”‚   â”œâ”€â”€ retrieval.py             # Hybrid retrieval system (semantic + keyword)
â”‚   â”œâ”€â”€ context_manager.py       # Context and execution tracking
â”‚   â”œâ”€â”€ data_generator.py        # Mock X data generator
â”‚   â”œâ”€â”€ config.py                # Configuration settings
â”‚   â”œâ”€â”€ tools.py                 # Tool registry and definitions
â”‚   â”œâ”€â”€ routes/                  # API route handlers
â”‚   â”‚   â”œâ”€â”€ __init__.py          # Router definitions
â”‚   â”‚   â”œâ”€â”€ main.py              # Main routes (health, static files)
â”‚   â”‚   â”œâ”€â”€ query.py             # Query endpoints (single, compare-models)
â”‚   â”‚   â””â”€â”€ evaluation.py        # Evaluation endpoints
â”‚   â”œâ”€â”€ services/                # Business logic services
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ agent_service.py     # Agent lifecycle management
â”‚   â”œâ”€â”€ utils/                   # Utility modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ errors.py            # Error handling
â”‚   â”‚   â”œâ”€â”€ response.py          # Response formatting
â”‚   â”‚   â””â”€â”€ truncation.py        # Text truncation utilities
â”‚   â””â”€â”€ evaluation/              # Evaluation framework
â”‚       â”œâ”€â”€ evaluator.py         # Batch evaluation runner
â”‚       â”œâ”€â”€ compare_models.py    # Model comparison script
â”‚       â”œâ”€â”€ metrics.py           # Metrics collection
â”‚       â”œâ”€â”€ test_queries.json    # Test query suite (40 queries)
â”‚       â””â”€â”€ results/             # Evaluation results output
â”œâ”€â”€ client/                      # Client-side code
â”‚   â””â”€â”€ static/                  # Web UI files
â”‚       â”œâ”€â”€ index.html           # Main query interface
â”‚       â”œâ”€â”€ tweets.html         # Tweets browsing page
â”‚       â”œâ”€â”€ style.css            # Styles
â”‚       â””â”€â”€ script.js            # Frontend JavaScript
â”œâ”€â”€ data/                        # Generated mock data
â”‚   â”œâ”€â”€ mock_x_data.json        # Main dataset (~3800 posts)
â”‚   â””â”€â”€ .embeddings_cache/      # Cached embeddings
â”œâ”€â”€ output/                      # Research results
â”‚   â””â”€â”€ research_result.json
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env.example                 # Environment variables template
â”œâ”€â”€ Dockerfile                   # Docker configuration
â”œâ”€â”€ docker-compose.yml           # Docker Compose configuration
â””â”€â”€ README.md                    # This file
```

### Key Components

- **`agent.py`**: Implements the state machine workflow with autonomous decision-making
- **`retrieval.py`**: Hybrid search combining semantic (embeddings) and keyword matching
- **`tools.py`**: Dynamic tool calling system (keyword_search, semantic_search, hybrid_search, user_profile_lookup, temporal_trend_analyzer, filter_by_metadata)
- **`context_manager.py`**: Manages conversation history and token limits
- **`grok_client.py`**: Handles Grok API calls with streaming and tool calling support
- **`routes/query.py`**: API endpoints for single queries and parallel model comparison
- **`client/static/`**: Web UI with real-time progress updates via Server-Sent Events

## ğŸ”§ Configuration

Edit `config.py` to customize:

- **Model Selection**: Choose which Grok models to use for each task
- **Retrieval Settings**: Adjust hybrid search weights, top-k results
- **Agent Settings**: Max iterations, context limits, temperature
- **Data Settings**: Mock data size, file paths

### Model Selection Strategy

The framework uses different Grok models for different tasks:

- **Planning & Analysis**: `grok-4-fast-reasoning` (fast reasoning, 2M context, $0.20/$0.50)
- **Classification**: `grok-4-fast-reasoning` (consistent model)
- **Refinement**: `grok-4-fast-reasoning` (fast reasoning)
- **Summarization**: `grok-4-fast-reasoning` (high-quality summaries)

*Note: Adjust model names in `config.py` based on available models from xAI*

## ğŸ“Š Example Queries

The agent can handle diverse query types:

### Trend Analysis
```
"What are people saying about AI safety?"
"What topics are trending in tech discussions?"
```

### Information Extraction
```
"Find all posts mentioning GPT-4 from verified accounts"
"What are the most liked posts about climate change?"
```

### Comparative Analysis
```
"Compare discussions about Python vs JavaScript"
"What's the difference in sentiment between crypto and traditional finance?"
```

### Temporal Analysis
```
"How has sentiment about remote work changed over time?"
"What were the peak discussion topics last week?"
```

## ğŸ” How It Works

### 1. Planning Phase
Grok analyzes the query and creates a structured plan:
- Classifies query type
- Identifies required tools
- Defines success criteria
- Estimates complexity

### 2. Execution Phase
Hybrid retrieval system:
- **Semantic Search**: Uses sentence transformers for meaning-based search
- **Keyword Search**: Traditional keyword matching with TF-IDF-like scoring
- **Hybrid**: Combines both methods with configurable weights

### 3. Analysis Phase
Grok performs deep analysis:
- Identifies main themes
- Extracts key insights
- Analyzes sentiment distribution
- Evaluates data quality
- Assigns confidence score

### 4. Refinement Phase
If confidence is low (< 0.8), Grok decides:
- Whether refinement is needed
- What additional steps to take
- Expected confidence improvement

The agent iteratively refines until confidence is sufficient or max iterations reached.

### 5. Summarization Phase
Grok generates final comprehensive summary:
- Executive summary
- Key findings
- Detailed analysis
- Limitations
- Recommendations

## ğŸ“ Data Flow and Tool Calls

### End-to-end data flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     POST /api/query      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     progress_callback     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web UI    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  FastAPI        â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚   Agent      â”‚
â”‚  (script.js)â”‚                          â”‚  routes/query   â”‚      (event_type, data)   â”‚  (agent.py)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                           â”‚                                            â”‚
       â”‚  SSE stream (data: {...}\n\n)              â”‚  run_workflow(query)                      â”‚
       â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                            â”‚
       â”‚                                           â”‚  AgentService.get_agent()                 â”‚
       â”‚                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
       â”‚                                                                                       â”‚
       â”‚                                                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                                                     â”‚  State machine: PLAN â†’ EXECUTE â†’   â”‚
       â”‚                                                                     â”‚  ANALYZE â†’ EVALUATE â†’ REFINE /     â”‚
       â”‚                                                                     â”‚  CRITIQUE â†’ SUMMARIZE â†’ COMPLETE   â”‚
       â”‚                                                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                                                                       â”‚
       â”‚                                                                     Plan-based        â”‚ Dynamic tool
       â”‚                                                                     (retriever only)  â”‚ calling (Grok API
       â”‚                                                                           â”‚          â”‚ + ToolRegistry)
       â”‚                                                                           â–¼          â–¼
       â”‚                                                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                                                     â”‚Hybrid    â”‚  â”‚ Grok API     â”‚
       â”‚                                                                     â”‚Retriever â”‚  â”‚ (tools=...)  â”‚
       â”‚                                                                     â”‚tools.py  â”‚  â”‚ tools.py     â”‚
       â”‚                                                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Request**: User submits a query via the Web UI â†’ `POST /api/query` (or `/api/query/compare-models` for multi-model).
2. **Orchestration**: The route starts `run_workflow` in a background thread and sets `agent.progress_callback` to push events into a queue.
3. **Streaming**: A generator consumes the queue and emits Server-Sent Events (`data: {"type": "...", ...}\n\n`) to the client. The UI updates logs and progress in real time from these events.
4. **Execution**: The agent runs the state machine. **Execute** either uses **plan-based** retrieval (see below) or **dynamic tool calling** (Grok selects tools iteratively).
5. **Response**: When the workflow reaches `COMPLETE`, the final result (summary, findings, etc.) is sent as the last SSE payload (or in the compare-models response). The UI displays it in the Summary tab.

### Two execution modes

| **Aspect** | **Plan-based execution** | **Dynamic tool calling** |
|---|---|---|
| **When** | Default. Used when `use_tool_calling=false` or when the plan is â€œsimpleâ€ (e.g. low complexity, â‰¤2 steps, info_extraction/sentiment). | Used only when the planner sets `use_tool_calling=true` *and* the plan is not overridden as simple. |
| **Who drives** | The planâ€™s `steps` (from `plan()`). The agent loops over steps and calls the retriever directly. | Grok API. The model chooses tools per turn; the agent runs them and appends results to the conversation. |
| **Tools** | `hybrid_search`, `keyword_search`, `filter_by_metadata` via `HybridRetriever` / `retrieval` (no Grok tool-calling). | All tools in `ToolRegistry`: see below. |
| **Progress** | `executing` events with `status: started | completed`, `results_count`. No `tool_calls` / `tool_calling_mode`. | Same, plus `tool_calling_mode: true`, `tool_calls` (list of `{name, args, success, ...}`), and per-call â€œCalling tool: Xâ€ / â€œCompleted N tool call(s)â€ messages. |
| **Logs** | â€œRetrieving relevant dataâ€¦â€ â†’ â€œRetrieved N itemsâ€. No â€œTools usedâ€ section. | â€œStarting dynamic tool callingâ€¦â€ â†’ â€œCalling tool: Xâ€ / â€œCompleted N tool call(s)â€ â†’ â€œTool calling finished. Retrieved N resultsâ€. â€œTools usedâ€ appears in the Logs tab when `tool_calls` is present. |

Simple multi-step queries (e.g. â€œSummarize sentiment on cryptoâ€) typically use **plan-based** execution, so you will not see tool-call entries in the logs. To see **tool calling** in the UI, use **complex, multi-step** prompts (e.g. â€œCompare sentiment about crypto vs traditional finance, then filter by verified accounts, then show how it changed over the last 7 daysâ€ or â€œWhat do verified accounts say about sports? Filter by high engagement.â€).

### Available tools (`tools.py`)

Used in **dynamic tool calling**; in **plan-based** mode, only the retriever-based logic (hybrid/keyword/filter) is used.

| Tool | Purpose |
|------|--------|
| `keyword_search` | Keyword/phrase matching. Good for exact terms, hashtags. |
| `semantic_search` | Embedding-based similarity. Good for concepts and paraphrases. |
| `hybrid_search` | Combines keyword + semantic. Default search in tool-calling mode. |
| `user_profile_lookup` | Posts by author (name/id). Optional `verified_only`. |
| `temporal_trend_analyzer` | Time-windowed analysis (e.g. `days_back`, date range). |
| `filter_by_metadata` | Filter by sentiment, `min_engagement`, `verified_only`, category, language, etc. |

`ToolRegistry` holds tool definitions (OpenAI-style function schema), implements `run_tool(name, arguments)`, and uses `HybridRetriever` and the full dataset for search/filter operations.

### Tool-calling loop (dynamic mode only)

1. Agent sends the research query to Grok with `tools` and `tool_choice="auto"`.
2. Grok returns either a text reply or `tool_calls` (or both).
3. If there are no `tool_calls`, the loop ends; aggregated results are passed to **Analyze**.
4. Otherwise, for each `tool_call`:
   - `ToolRegistry.run_tool(name, arguments)` is invoked.
   - Results are appended to the conversation as tool messages.
   - Progress is emitted (`tool_calling`, `tool_calls` history) so the UI can show â€œCalling tool: Xâ€ and â€œTools usedâ€.
5. The updated `messages` are sent back to Grok; repeat until no more `tool_calls` or `max_tool_calls` is reached.

After the loop, the final flattened result list is fed into **Analyze** â†’ **Evaluate** â†’ **Refine** / **Critique** â†’ **Summarize** exactly as in plan-based execution.

## ğŸ§ª Testing

Run example queries:
```bash
# Test trend analysis
python main.py --query "What are people saying about AI?"

# Test information extraction
python main.py --query "Find posts about Python from verified accounts"

# Test comparison
python main.py --query "Compare sentiment about crypto vs stocks"
```

## ğŸ“ˆ Evaluation Framework

The system includes a comprehensive evaluation framework for testing agent performance across multiple queries and comparing different Grok models.

### Quick Start

**Run batch evaluation:**
```bash
cd server/evaluation
python evaluator.py --max-queries 10
```

**Compare models:**
```bash
python compare_models.py --max-queries 5
```

### Features

- **40 Test Queries**: Diverse queries covering trend analysis, info extraction, comparison, temporal analysis, sentiment, edge cases, and more
- **Metrics Collection**: 
  - Completion rate (% successfully completed)
  - Step efficiency (avg steps, refinement iterations, replan count)
  - Summary quality (confidence scores, summary length)
  - Autonomy metrics (replan rate, refinement rate, critique pass rate)
- **Model Comparison**: Compare performance across different Grok model variants
- **Category Breakdown**: Metrics broken down by query category and complexity level

### Test Query Suite

The `server/evaluation/test_queries.json` contains 40 queries:
- **Categories**: trend_analysis, info_extraction, comparison, temporal, sentiment, complex, edge_case, multilingual, specific, broad, filtering, synthesis, etc.
- **Complexity**: low (4), medium (18), high (18)
- **Edge Cases**: sarcasm detection, ambiguity resolution, conflicting sources, threaded discussions

### Metrics Tracked

- **Completion Rate**: % of queries successfully completed
- **Step Efficiency**: Number of steps per query, refinement iterations, replan cycles
- **Confidence Scores**: Final confidence in results, high confidence rate
- **Token Usage**: Total tokens consumed per query
- **Autonomy Score**: How well agent handles queries independently (0-1 scale)

Results are saved to `server/evaluation/results/` with detailed metrics and individual query results.

See `server/evaluation/README.md` for detailed documentation.

## ğŸ› Troubleshooting

### API Key Issues
```
Error: GROK_API_KEY not found
```
**Solution**: Set `GROK_API_KEY` in `.env` file or environment variable

### API Errors
```
âŒ Grok API Error: ...
```
**Solutions**:
- Check your API key is valid
- Verify you have credits in your xAI account
- Check rate limits
- Verify model names match available models

### No Results Found
If retrieval returns no results:
- Check your mock data file exists
- Verify data format matches expected structure
- Try broader search terms

### Low Confidence
If confidence scores are consistently low:
- Increase mock data size
- Adjust hybrid search weights
- Increase max refinement iterations
- Check data quality

## ğŸ” Security Notes

- Never commit `.env` file with API keys
- Use environment variables in production
- Rotate API keys regularly
- Monitor token usage to avoid unexpected costs

## ğŸ“ Model Selection Rationale

### Why grok-4-fast-reasoning for Planning?
Planning requires complex reasoning to break down queries. `grok-4-fast-reasoning` provides strong reasoning at 45x lower cost than `grok-3` ($0.20/$0.50 vs $3/$15 per 1M tokens) with a 15x larger context window (2M vs 131K tokens).

### Why grok-4-fast-reasoning for Analysis?
Deep analysis needs sophisticated reasoning to identify patterns and insights. The fast reasoning model maintains quality while significantly reducing costs.

### Why grok-4-fast-reasoning for Refinement?
Refinement decisions require understanding context and determining optimal next steps. The larger context window (2M tokens) allows for better context management.

### Why grok-4-fast-reasoning for Summarization?
High-quality summaries need strong language understanding and synthesis capabilities. The fast reasoning model provides excellent quality at a fraction of the cost.

**Note**: The framework uses `grok-4-fast-reasoning` for optimal cost/performance balance. It's 45x cheaper than `grok-3` while maintaining strong reasoning capabilities.

*Note: If lighter/faster models are available, you can use them for classification tasks to reduce costs.*

## ğŸš¢ Deployment

### Docker (Coming Soon)
```bash
docker build -t grok-agent .
docker run -e GROK_API_KEY=your_key grok-agent
```

### Docker Compose (Coming Soon)
```bash
docker-compose up
```

## ğŸ“„ License

This project is created for the Grok engineering assessment.

## ğŸ¤ Contributing

This is an assessment project. For questions or issues, contact the assessment team.

## ğŸ“§ Contact

For questions about this assessment:
- Payton: payton@x.ai
- Ideshpande: ideshpande@x.ai

---

**Built with â¤ï¸ using Grok by xAI**
